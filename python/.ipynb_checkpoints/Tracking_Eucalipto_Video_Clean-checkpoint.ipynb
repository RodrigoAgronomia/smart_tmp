{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import cv2\n",
    "import time\n",
    "import json\n",
    "import pickle\n",
    "import numpy as np\n",
    "import torch\n",
    "from torch.autograd import Variable\n",
    "from matplotlib import pyplot as plt\n",
    "from cnn import SegmentationModel as net"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "print(device)\n",
    "print('Torch:' + torch.__version__)\n",
    "print('Opencv:' + cv2.__version__)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from queue import Queue\n",
    "from threading import Thread"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def colorir(cat):\n",
    "    h, w = cat.shape[:2]\n",
    "    msk = np.zeros((h,w,3), dtype = 'uint8')\n",
    "    msk[cat == 0] = [255,255,255]\n",
    "    msk[cat == 1] = [0,255,0]\n",
    "    msk[cat == 2] = [0,0,255]\n",
    "    msk[cat == 3] = [255,255,255]\n",
    "    return(msk)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def transform(x):\n",
    "    x = x.copy()\n",
    "    x = x.astype('float')\n",
    "    x -= 128\n",
    "    x /= 35\n",
    "    x = np.moveaxis(x, 2, 0)\n",
    "    x = torch.unsqueeze(torch.from_numpy(x), 0)\n",
    "    x = Variable(x).to(device, dtype=torch.float)\n",
    "    return(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_cat(frame):\n",
    "    img = transform(frame)\n",
    "    pred, feat = model(img)\n",
    "    pred = pred.cpu().data.numpy()\n",
    "    pred = np.moveaxis(pred, 1, 3)\n",
    "    pred = np.squeeze(pred)\n",
    "    cat = np.argmax(pred, 2).astype('uint8')\n",
    "    return(cat)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Tracking:\n",
    "        \n",
    "    def __init__(self, w, h, scale):\n",
    "        self.w = w\n",
    "        self.h = h\n",
    "        self.scale = scale\n",
    "        self.history = {}\n",
    "        self.frame_number = 0\n",
    "        self.n_plantas = 0\n",
    "        self.speed = 0\n",
    "        self.last_speed = 0\n",
    "        self.speed_avg = np.zeros(5)\n",
    "        \n",
    "        self.plant_boxes = np.empty([0, 4])\n",
    "        self.stem_boxes = np.empty([0, 4])\n",
    "        \n",
    "    def __bb_iou__(self, boxes1, boxes2):\n",
    "        x11, y11, x12, y12 = np.split(boxes1, 4, axis=1)\n",
    "        x21, y21, x22, y22 = np.split(boxes2, 4, axis=1)\n",
    "        xA = np.maximum(x11, np.transpose(x21))\n",
    "        yA = np.maximum(y11, np.transpose(y21))\n",
    "        xB = np.minimum(x12, np.transpose(x22))\n",
    "        yB = np.minimum(y12, np.transpose(y22))\n",
    "        interArea = np.maximum((xB - xA + 1), 0) * np.maximum((yB - yA + 1), 0)\n",
    "        boxAArea = (x12 - x11 + 1) * (y12 - y11 + 1)\n",
    "        boxBArea = (x22 - x21 + 1) * (y22 - y21 + 1)\n",
    "        iou = interArea / (boxAArea + np.transpose(boxBArea) - interArea)\n",
    "        return iou\n",
    "\n",
    "    def __nms__(self, boxes, overlapThresh = 0.1):\n",
    "        # if there are no boxes, return an empty list\n",
    "        if len(boxes) == 0:\n",
    "            return(np.empty([0, 4]))\n",
    "\n",
    "        boxes = boxes.astype(\"float\")\n",
    "\n",
    "        # initialize the list of picked indexes\t\n",
    "        pick = []\n",
    "\n",
    "        # grab the coordinates of the bounding boxes\n",
    "        x1 = boxes[:,0]\n",
    "        y1 = boxes[:,1]\n",
    "        x2 = boxes[:,2]\n",
    "        y2 = boxes[:,3]\n",
    "\n",
    "        # compute the area of the bounding boxes and sort the bounding\n",
    "        # boxes by the bottom-right y-coordinate of the bounding box\n",
    "        area = (x2 - x1 + 1) * (y2 - y1 + 1)\n",
    "        idxs = np.argsort(y2)\n",
    "\n",
    "        # keep looping while some indexes still remain in the indexes\n",
    "        # list\n",
    "        while len(idxs) > 0:\n",
    "            # grab the last index in the indexes list and add the\n",
    "            # index value to the list of picked indexes\n",
    "            last = len(idxs) - 1\n",
    "            i = idxs[last]\n",
    "            pick.append(i)\n",
    "\n",
    "            # find the largest (x, y) coordinates for the start of\n",
    "            # the bounding box and the smallest (x, y) coordinates\n",
    "            # for the end of the bounding box\n",
    "            xx1 = np.maximum(x1[i], x1[idxs[:last]])\n",
    "            yy1 = np.maximum(y1[i], y1[idxs[:last]])\n",
    "            xx2 = np.minimum(x2[i], x2[idxs[:last]])\n",
    "            yy2 = np.minimum(y2[i], y2[idxs[:last]])\n",
    "\n",
    "            # compute the width and height of the bounding box\n",
    "            w = np.maximum(0, xx2 - xx1 + 1)\n",
    "            h = np.maximum(0, yy2 - yy1 + 1)\n",
    "\n",
    "            # compute the ratio of overlap\n",
    "            overlap = (w * h) / area[idxs[:last]]\n",
    "\n",
    "            # delete all indexes from the index list that have\n",
    "            idxs = np.delete(idxs, np.concatenate(([last],\n",
    "                np.where(overlap > overlapThresh)[0])))\n",
    "\n",
    "        # return only the bounding boxes that were picked using the\n",
    "        # integer data type\n",
    "        return boxes[pick].astype(\"int64\")\n",
    "\n",
    "    def __get_bboxes__(self, msk, minArea, maxArea, minDst, maxDst):\n",
    "        contours, hierarchy = cv2.findContours(msk, cv2.RETR_TREE, cv2.CHAIN_APPROX_SIMPLE)\n",
    "        bboxes = []\n",
    "        for cnt in contours:\n",
    "            area = cv2.contourArea(cnt)\n",
    "            bbox = cv2.boundingRect(cnt)\n",
    "            x,y,w,h = np.array(bbox)\n",
    "            if area >  minArea and area < maxArea:\n",
    "                if (x > minDst) and ((x+w) < maxDst):\n",
    "                    bboxes.append([x,y,x+w,y+h])\n",
    "        bboxes = self.__nms__(np.array(bboxes))\n",
    "        return(bboxes)\n",
    "\n",
    "    def __match__(self, old, new):\n",
    "        areas = None\n",
    "        if new.size > 0 and old.size > 0 :\n",
    "            areas = self.__bb_iou__(new, old)\n",
    "        return(areas)\n",
    "        \n",
    "    def __update_speed__(self, dst):\n",
    "        self.last_speed += dst\n",
    "        self.last_speed = np.max([-1, np.min([10, self.last_speed])])\n",
    "        self.speed_avg = np.insert(self.speed_avg, 0, self.last_speed)[:5]\n",
    "        self.speed = np.mean(self.speed_avg)\n",
    "        \n",
    "    def __update__(self, old, new, areas, calc_speed = False):\n",
    "        tmp = np.empty([0, 4])\n",
    "        mcrit = np.ones(len(new), dtype=bool)\n",
    "\n",
    "        if new.size > 0:\n",
    "            if old.size > 0 :\n",
    "                ncrit = np.where(areas.max(0) > 0)\n",
    "                acrit = areas.argmax(0)[ncrit]        \n",
    "                \n",
    "                if calc_speed:\n",
    "                    # Utiliza os bbox correspondentes para calcular a velocidade (px/frame):\n",
    "                    # Obs: O calculo eh mais estavel com base nos tubetes\n",
    "                    dst = np.nan\n",
    "                    try:\n",
    "                        dst = np.mean(new[acrit, [0,2]] - old[ncrit, [0,2]])\n",
    "                    except:\n",
    "                        print('Dst Error')\n",
    "                        \n",
    "                    if not np.isnan(dst):\n",
    "                        self.__update_speed__(dst)\n",
    "\n",
    "                old[ncrit] = new[acrit]\n",
    "                mcrit[acrit] = False\n",
    "            else:\n",
    "                old = new\n",
    "            tmp = new[mcrit]\n",
    "   \n",
    "        return([old, tmp])\n",
    "\n",
    "    def get_frame_dict(self, pb, sb):\n",
    "\n",
    "        frame_str = {}\n",
    "\n",
    "        for idx, (pbb, sbb) in enumerate(zip(pb, sb)):\n",
    "            pbb = pbb.copy()\n",
    "            sbb = sbb.copy()\n",
    "            pidx = idx + self.n_plantas + 1\n",
    "            pbb[3] = sbb[1] + 10\n",
    "            plant_bb = np.int0(pbb * self.scale).tolist()\n",
    "\n",
    "            xm = int(np.mean(sbb[[0,2]]))\n",
    "            sbb[[0,2]] = xm + np.array([-10,10])\n",
    "            sbb[[1,3]] = [sbb[1] - 5, sbb[1] + 5]                    \n",
    "            stem_bb = np.int0(sbb * self.scale).tolist()\n",
    "            \n",
    "            frame_str['P{}'.format(pidx)] = {'Plant':plant_bb, 'Stem':stem_bb}\n",
    "        return(frame_str)\n",
    "\n",
    "\n",
    "    def __prep_next__(self, old, tmp):\n",
    "        old = np.concatenate([old, tmp])\n",
    "        old = self.__nms__(old)\n",
    "        if old.size > 0:\n",
    "            old += np.int0(self.speed * np.ones((len(old), 1)) * np.array([[1,0,1,0]]))\n",
    "            old = old[old[:,0].argsort()[::-1]]\n",
    "        return(old)\n",
    "\n",
    "    def __remove__(self):\n",
    "        if self.stem_boxes.size > 0:\n",
    "            # Remove os bbox que estarao fora da imagem, e conta como uma nova planta:\n",
    "            fcrit = self.stem_boxes[:,2] > self.w\n",
    "            self.plant_boxes = self.plant_boxes[np.logical_not(fcrit)]\n",
    "            self.stem_boxes = self.stem_boxes[np.logical_not(fcrit)]\n",
    "            self.n_plantas += fcrit.sum()         \n",
    "\n",
    "    def __validate__(self, pb, sb):\n",
    "        pbb = np.empty([0, 4])\n",
    "        sbb = np.empty([0, 4])\n",
    "        if pb.size > 0 and sb.size > 0:\n",
    "            pb = pb[pb[:,0].argsort()[::-1]]\n",
    "            sb = sb[sb[:,0].argsort()[::-1]]\n",
    "            areas = self.__bb_iou__(pb, sb)\n",
    "            nidx = [(pbix, sbix) for pbix, sbix in enumerate(areas.argmax(1)) if areas.max(1)[pbix] > 0]\n",
    "            if len(nidx) > 0:\n",
    "                pbb = np.array([pb[pbix] for pbix, sbix in nidx])\n",
    "                sbb = np.array([sb[sbix] for pbix, sbix in nidx])\n",
    "        return(pbb, sbb)\n",
    "        \n",
    "    def update(self, cat):\n",
    "\n",
    "        plant_msk = np.isin(cat, [1,2]).astype('uint8')\n",
    "        new_pb = self.__get_bboxes__(plant_msk, 50, 50000, 0.01*self.w, 0.99*self.w)\n",
    "        \n",
    "        stem_msk = (cat == 2).astype('uint8')\n",
    "        new_sb = self.__get_bboxes__(stem_msk, 10, 10000, 0.01*self.w, 0.99*self.w)\n",
    "        \n",
    "        new_pb, new_sb = self.__validate__(new_pb, new_sb)\n",
    "        \n",
    "        area_crit = self.__match__(self.stem_boxes, new_sb)\n",
    "        old_pb, tmp_pb = self.__update__(self.plant_boxes, new_pb, area_crit, calc_speed = False)\n",
    "        old_sb, tmp_sb = self.__update__(self.stem_boxes, new_sb, area_crit, calc_speed = True)\n",
    "        \n",
    "        frame_str = self.get_frame_dict(old_pb, old_sb)\n",
    "        self.history['Frame{:04d}'.format(self.frame_number)] = frame_str\n",
    "        self.frame_number = +1\n",
    "        \n",
    "        new_pb = self.__prep_next__(old_pb, tmp_pb)\n",
    "        new_sb = self.__prep_next__(old_sb, tmp_sb)\n",
    "        self.plant_boxes, self.stem_boxes = trk.__validate__(new_pb, new_sb)\n",
    "        \n",
    "        self.__remove__()\n",
    "        \n",
    "        return(frame_str)\n",
    "        \n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class SaveFrame(Thread):\n",
    "    def __init__(self):\n",
    "        self.running = True\n",
    "        self.q = Queue()\n",
    "        Thread.__init__(self, name='SaveFrame')\n",
    "    \n",
    "    def run(self):\n",
    "        while self.running:\n",
    "            if not sf.q.empty():\n",
    "                frame_str,  frame = self.q.get()\n",
    "                print(frame_str)\n",
    "            else:\n",
    "                time.sleep(1)\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# sf = SaveFrame()\n",
    "# sf.start()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# sf.q.put(['av', 'b'])\n",
    "# sf.q.empty()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_classes = 4\n",
    "\n",
    "# Atribui o modelo\n",
    "model = net.EESPNet_Seg(n_classes, s=0.5, pretrained='', gpus=1)\n",
    "model = model.to(device)\n",
    "model.load_state_dict(torch.load('../data/Trackingff.pth',map_location=device))\n",
    "\n",
    "\n",
    "# set to evaluation mode\n",
    "model.eval()\n",
    "\n",
    "print('Modelo Ok')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "frames_dir = '/home/rodrigo7/Notebook/Datasets/Eucalyptus2/Plantas/'\n",
    "msks_dir = '/home/rodrigo7/Notebook/Datasets/Eucalyptus2/Pred/'\n",
    "video_dir = '/home/rodrigo7/Notebook/Datasets/Eucalyptus2/Videos/'\n",
    "video_dir = '/home/rodrigo7/Notebook/SmartVision/Eucalipto/VideosLR'\n",
    "save_dir = '/home/rodrigo7/Notebook/Datasets/Eucalyptus2/Videos_Pred/'\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# input_height = 1080\n",
    "# input_width = 1920\n",
    "\n",
    "# output_height = 192\n",
    "# output_width = 256\n",
    "\n",
    "# ioh, iow = input_height/output_height, input_width/output_width\n",
    "# scale = np.array([iow, ioh, iow, ioh])\n",
    "\n",
    "video_files = sorted(os.listdir(video_dir))\n",
    "video_files = [os.path.join(video_dir, v) for v in video_files if not v.endswith(('.json', '_bb.avi', '_bblr.avi'))]\n",
    "\n",
    "font = cv2.FONT_HERSHEY_SIMPLEX  \n",
    "fourcc = cv2.VideoWriter_fourcc(*'XVID')\n",
    "  \n",
    "print(video_files)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "video_file = '/home/rodrigo7/Notebook/SmartVision/Eucalipto/VideosLR/eCAM_video_20181011_183203.avi'\n",
    "\n",
    "for video_file in video_files:\n",
    "    save_file = os.path.join(save_dir, os.path.basename(video_file))\n",
    "    json_file = save_file.replace('.avi', '.json')\n",
    "\n",
    "    video_history = {}\n",
    "\n",
    "    output_height = 192\n",
    "    output_width = 256\n",
    "\n",
    "    out = cv2.VideoWriter(save_file, fourcc, 30.0, (output_width, output_height))\n",
    "    print(save_file)\n",
    "\n",
    "    cap = cv2.VideoCapture(video_file)\n",
    "    n_frames = int(cap.get(cv2.CAP_PROP_FRAME_COUNT))\n",
    "    input_height = int(cap.get(cv2.CAP_PROP_FRAME_HEIGHT))\n",
    "    input_width = int(cap.get(cv2.CAP_PROP_FRAME_WIDTH))\n",
    "\n",
    "\n",
    "    ioh, iow = input_height/output_height, input_width/output_width\n",
    "    scale = np.array([iow, ioh, iow, ioh])\n",
    "    trk = Tracking(output_width, output_height, scale)\n",
    "\n",
    "    # n_frames = 200\n",
    "    t_start = time.time()                 \n",
    "    for i in range(n_frames):\n",
    "        print(i)\n",
    "        start_time = time.time()\n",
    "        res, frameo = cap.read()\n",
    "        frame = cv2.resize(frameo, (output_width, output_height))\n",
    "        cat = get_cat(frame)\n",
    "\n",
    "        framemsk = frame.copy()\n",
    "        mskf = np.zeros_like(cat)\n",
    "\n",
    "        # apply the overlay\n",
    "        alpha = 0.5\n",
    "        pred = colorir(cat)\n",
    "        framec = cv2.resize(pred, (output_width, output_height))\n",
    "        cv2.addWeighted(framec, alpha, frame, 1 - alpha, 0, frame)\n",
    "\n",
    "        # Update bounding boxes of the tracking module and\n",
    "        # get the dictionary with bounding boxes from the tracking module:\n",
    "        frame_str = trk.update(cat)\n",
    "        print(frame_str)\n",
    "\n",
    "        # Adiciona ao dicionario do video as informacoes desse frame:\n",
    "        video_history['Frame{:04d}'.format(i)] = frame_str\n",
    "        for p in frame_str.keys():\n",
    "            f_bbox = frame_str.get(p)\n",
    "            pbox = np.int0(f_bbox.get('Plant'))\n",
    "            sbox = np.int0(f_bbox.get('Stem'))\n",
    "            plantf_name = '_{}_F{:04d}.jpg'.format(p, i)\n",
    "            plant_file = frames_dir + plantf_name\n",
    "    #         cv2.imwrite(plant_file,frameo[pbox[1]:pbox[3], pbox[0]:pbox[2]])\n",
    "\n",
    "            pbb = np.int0(pbox / trk.scale)\n",
    "            frame = cv2.rectangle(frame,(pbb[0], pbb[1]), (pbb[2], pbb[3]),(0,0,255), 2)\n",
    "            cv2.putText(frame, p,(int(np.mean(pbb[[0,2]])), pbb[1]), font, 0.5,(255,255,255),1,cv2.LINE_AA)\n",
    "\n",
    "            sbb = np.int0(sbox / trk.scale)\n",
    "            frame = cv2.rectangle(frame,(sbb[0], sbb[1]),(sbb[2], sbb[3]),(255,0,0), 2)\n",
    "            cv2.putText(frame, p,(int(np.mean(sbb[[0,2]])), sbb[3]), font, 0.5,(255,255,255),1,cv2.LINE_AA)\n",
    "\n",
    "\n",
    "        # Nessa parte vou adicionar o outro modelo, que vai fazer a classificacao:\n",
    "        # classificar(frame, planta)\n",
    "\n",
    "\n",
    "        # Estou salvando apenas os frames com planta e movimento detectados:\n",
    "    #     if len(frame_str) > 0:\n",
    "        out.write(frame)\n",
    "\n",
    "        t_now = time.time()\n",
    "    #     cv2.imwrite(msks_dir + 'F{:04d}.png'.format(i), mskf)\n",
    "    #     cv2.imwrite(msks_dir + 'F{:04d}.jpg'.format(i), framemsk)\n",
    "\n",
    "        fps = i /(t_now - t_start)\n",
    "        if i % 10 == 0:\n",
    "            print('Running at {} FPS'.format(fps))\n",
    "            print(\"Speed:\" + str(trk.speed))\n",
    "\n",
    "    cap.release()\n",
    "    out.release()\n",
    "\n",
    "    # Salva o dicionario em json com as informacoes desse video:\n",
    "    # with open(json_file, 'w') as outfile:\n",
    "    #     json.dump(video_history, outfile)\n",
    "\n",
    "    time_taken = time.time() - start_time\n",
    "    print('PreProc time: %.2f' % time_taken)  \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.imshow(frame)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
